{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Redset Workload Forecasting\n",
    "\n",
    "## What is Redset?\n",
    "Redset is a dataset released by Amazon in 2024, comprising three months of user query metadata from a selected sample of Amazon Redshift instances. It includes query metadata for **200 provisioned and 200 serverless instances**, offering insights into user interactions with these database services. While not representative of the entire Redshift fleet, Redset serves as a valuable resource for developing **new benchmarks and exploring machine learning techniques**, such as **workload forecasting**, tailored to these specific workloads.\n",
    "\n",
    "## What we perform in this notebook?\n",
    "\n",
    "In this notebook, we analyze **Amazon Redset**, a dataset containing query metadata from Amazon Redshift instances, to explore **workload forecasting techniques** for **intelligent resource scaling**. Our primary objectives are:\n",
    "\n",
    "### 1. Baseline Model Evaluation\n",
    "- We evaluate **traditional forecasting baselines**, such as:\n",
    "  - **AutoGluon DeepAR**\n",
    "  - **Seasonal Naive Models**\n",
    "- These models establish reference points for **workload prediction**.\n",
    "\n",
    "### 2. Development of RNN-based Forecasting Models\n",
    "- We implement **Recurrent Neural Network (RNN)-based models** to improve **forecasting accuracy**.\n",
    "- These models aim to **capture complex workload patterns** and **improve upon the baselines**.\n",
    "\n",
    "### 3. Comparison Between Baselines and RNN-based Approaches\n",
    "- Using the **Redset dataset**, we compare the performance of our **custom RNN models** with:\n",
    "  - **AutoGluon DeepAR**\n",
    "  - **Statistical forecasting methods** (e.g., ARIMA, ETS)\n",
    "- We use metrics such as **Q-error** and **forecast accuracy** to assess improvements.\n",
    "\n",
    "---\n",
    "\n",
    "### Reference\n",
    "For more details on the forecasting methodologies and benchmark comparisons, we refer to the **attached paper: \"Forecasting Algorithms for Intelligent Resource Scaling: An Experimental Analysis\"**.  \n",
    "This paper provides insights into **workload forecasting challenges**, evaluation metrics, and strategies for improving predictive accuracy in cloud environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagnikdas/GitHub/WF-ML/env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from utility.helpers import DataManager\n",
    "import visualization\n",
    "from utility.baseline_models import DeepAR\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "datamanager = DataManager('provisioned', 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data = datamanager.load_data()\n",
    "# Convert timestamp to datetime\n",
    "data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
    "# Sort the data by timestamp\n",
    "data = data.sort_values('timestamp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>query_count</th>\n",
       "      <th>runtime</th>\n",
       "      <th>bytes_scanned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48872</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147290</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98018</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147330</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 03:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>245.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98055</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146949</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-05-29 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>3488.0</td>\n",
       "      <td>1147.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146983</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-05-29 20:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>36908.0</td>\n",
       "      <td>26665.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48624</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-05-29 21:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97748</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-05-29 22:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48661</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-05-29 23:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2159 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        instance_id           timestamp  query_count  runtime  bytes_scanned\n",
       "48872            96 2024-03-01 00:00:00            1     17.0            0.0\n",
       "147290           96 2024-03-01 01:00:00            1     20.0            0.0\n",
       "98018            96 2024-03-01 02:00:00            1     17.0            0.0\n",
       "147330           96 2024-03-01 03:00:00            4    245.0          136.0\n",
       "98055            96 2024-03-01 04:00:00            1     17.0            0.0\n",
       "...             ...                 ...          ...      ...            ...\n",
       "146949           96 2024-05-29 19:00:00            4   3488.0         1147.0\n",
       "146983           96 2024-05-29 20:00:00            4  36908.0        26665.0\n",
       "48624            96 2024-05-29 21:00:00            1     17.0            0.0\n",
       "97748            96 2024-05-29 22:00:00            1     18.0            0.0\n",
       "48661            96 2024-05-29 23:00:00            1     17.0            0.0\n",
       "\n",
       "[2159 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualize data\n",
    "visualization.visualize_data(data)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train1 shape: (1919, 5)\n",
      "test1 shape: (168, 5)\n",
      "train2 shape: (2087, 5)\n",
      "test2 shape: (48, 5)\n",
      "instance_id                       96\n",
      "timestamp        2024-05-19 23:00:00\n",
      "query_count                        1\n",
      "runtime                         19.0\n",
      "bytes_scanned                    0.0\n",
      "Name: 141583, dtype: object\n",
      "instance_id                       96\n",
      "timestamp        2024-05-20 00:00:00\n",
      "query_count                       13\n",
      "runtime                      20678.0\n",
      "bytes_scanned                 3045.0\n",
      "Name: 190321, dtype: object\n",
      "instance_id                       96\n",
      "timestamp        2024-05-19 23:00:00\n",
      "query_count                        1\n",
      "runtime                         19.0\n",
      "bytes_scanned                    0.0\n",
      "Name: 141583, dtype: object\n",
      "instance_id                       96\n",
      "timestamp        2024-05-20 00:00:00\n",
      "query_count                       13\n",
      "runtime                      20678.0\n",
      "bytes_scanned                 3045.0\n",
      "Name: 190321, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Split into training and test data:\n",
    "# Following the approach in the paper (p. 132), for a cluster with N weeks of data, \n",
    "# the first train-test split includes N-2 weeks for training and the following week \n",
    "# for testing. The second train-test split contains the first N-1 weeks for training \n",
    "# and the following week for testing, representing a scenario of re-training a model \n",
    "# each week and forecasting for the next week\n",
    "\n",
    "train1, test1, train2, test2 = datamanager.train_test_split(data)\n",
    "\n",
    "print(f\"train1 shape: {train1.shape}\")\n",
    "print(f\"test1 shape: {test1.shape}\")\n",
    "print(f\"train2 shape: {train2.shape}\")\n",
    "print(f\"test2 shape: {test2.shape}\")\n",
    "\n",
    "print(train1.iloc[-1])\n",
    "print(test1.iloc[0])\n",
    "print(train1.iloc[-1])\n",
    "print(test1.iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model: DeepAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instance_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>query_count</th>\n",
       "      <th>runtime</th>\n",
       "      <th>bytes_scanned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48872</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 00:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147290</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 01:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98018</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 02:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147330</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 03:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>245.0</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98055</th>\n",
       "      <td>96</td>\n",
       "      <td>2024-03-01 04:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        instance_id           timestamp  query_count  runtime  bytes_scanned\n",
       "48872            96 2024-03-01 00:00:00            1     17.0            0.0\n",
       "147290           96 2024-03-01 01:00:00            1     20.0            0.0\n",
       "98018            96 2024-03-01 02:00:00            1     17.0            0.0\n",
       "147330           96 2024-03-01 03:00:00            4    245.0          136.0\n",
       "98055            96 2024-03-01 04:00:00            1     17.0            0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagnikdas/GitHub/WF-ML/env/lib/python3.11/site-packages/autogluon/timeseries/predictor.py:197: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  std_freq = pd.tseries.frequencies.to_offset(self.freq).freqstr\n",
      "Frequency 'H' stored as 'h'\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to '/Users/sagnikdas/GitHub/WF-ML/AutogluonModels/ag-20250216_120532'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing DeepARAutogluonTS Model...\n",
      "Training started using DeepAR...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:06 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.27 GB / 8.00 GB (15.9%)\n",
      "Disk Space Avail:   33.29 GB / 228.27 GB (14.6%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'DeepAR': {'batch_size': 32,\n",
      "                                'context_length': 12,\n",
      "                                'dropout_rate': 0.1,\n",
      "                                'epochs': 50,\n",
      "                                'hidden_size': 40,\n",
      "                                'learning_rate': 0.001,\n",
      "                                'num_layers': 2}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 12,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'query_count',\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 1920 rows (NaN fraction=0.1%), 1 time series. Median time series length is 1920 (min=1920, max=1920). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'query_count'\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-02-16 13:05:36\n",
      "Models that will be trained: ['DeepAR']\n",
      "Training timeseries model DeepAR. \n",
      "\tWarning: Exception caused DeepAR to fail during training... Skipping this model.\n",
      "\tdlopen(/Users/sagnikdas/GitHub/WF-ML/env/lib/python3.11/site-packages/mxnet/libmxnet.so, 0x0006): tried: '/Users/sagnikdas/GitHub/WF-ML/env/lib/python3.11/site-packages/mxnet/libmxnet.so' (not a mach-o file), '/System/Volumes/Preboot/Cryptexes/OS/Users/sagnikdas/GitHub/WF-ML/env/lib/python3.11/site-packages/mxnet/libmxnet.so' (no such file), '/Users/sagnikdas/GitHub/WF-ML/env/lib/python3.11/site-packages/mxnet/libmxnet.so' (not a mach-o file)\n",
      "Not fitting ensemble as no models were successfully trained.\n",
      "Training complete. Models trained: []\n",
      "Total runtime: 47.20 s\n",
      "Trainer has no fit models that can predict.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed using DeepAR.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Trainer has no fit models that can predict.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain(train1, target_column\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_count\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Generate predictions on the test data\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m predictions_df \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_column\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquery_count\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredictions:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(predictions_df\u001b[38;5;241m.\u001b[39mhead())\n",
      "File \u001b[0;32m~/GitHub/WF-ML/utility/baseline_models.py:80\u001b[0m, in \u001b[0;36mDeepAR.predict\u001b[0;34m(self, test_data, target_column)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel must be trained before making predictions.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     79\u001b[0m prepared_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_data(test_data, target_column)\n\u001b[0;32m---> 80\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepared_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# Extract forecasts for our single time series (item_id = \"item_1\").\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# The predictions DataFrame index is 'timestamp' and the columns include the forecast quantiles.\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# Here we compute the mean forecast and select quantiles for lower and upper bounds.\u001b[39;00m\n\u001b[1;32m     85\u001b[0m forecast \u001b[38;5;241m=\u001b[39m predictions\u001b[38;5;241m.\u001b[39mloc[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mitem_1\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/GitHub/WF-ML/env/lib/python3.11/site-packages/autogluon/timeseries/predictor.py:856\u001b[0m, in \u001b[0;36mTimeSeriesPredictor.predict\u001b[0;34m(self, data, known_covariates, model, use_cache, random_seed)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m known_covariates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    855\u001b[0m     known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_data_frame(known_covariates)\n\u001b[0;32m--> 856\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_learner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mreindex(original_item_id_order, level\u001b[38;5;241m=\u001b[39mITEMID)\n",
      "File \u001b[0;32m~/GitHub/WF-ML/env/lib/python3.11/site-packages/autogluon/timeseries/learner.py:188\u001b[0m, in \u001b[0;36mTimeSeriesLearner.predict\u001b[0;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    186\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_generator\u001b[38;5;241m.\u001b[39mtransform_future_known_covariates(known_covariates)\n\u001b[1;32m    187\u001b[0m known_covariates \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_covariates_with_forecast_index(known_covariates\u001b[38;5;241m=\u001b[39mknown_covariates, data\u001b[38;5;241m=\u001b[39mdata)\n\u001b[0;32m--> 188\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_trainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    190\u001b[0m \u001b[43m    \u001b[49m\u001b[43mknown_covariates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mknown_covariates\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    191\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    192\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    193\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    195\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHub/WF-ML/env/lib/python3.11/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:936\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.predict\u001b[0;34m(self, data, known_covariates, model, use_cache, random_seed, **kwargs)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     data: TimeSeriesDataFrame,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TimeSeriesDataFrame:\n\u001b[0;32m--> 936\u001b[0m     model_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_model_for_prediction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    937\u001b[0m     model_pred_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_pred_dict(\n\u001b[1;32m    938\u001b[0m         model_names\u001b[38;5;241m=\u001b[39m[model_name],\n\u001b[1;32m    939\u001b[0m         data\u001b[38;5;241m=\u001b[39mdata,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    942\u001b[0m         random_seed\u001b[38;5;241m=\u001b[39mrandom_seed,\n\u001b[1;32m    943\u001b[0m     )\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_pred_dict[model_name]\n",
      "File \u001b[0;32m~/GitHub/WF-ML/env/lib/python3.11/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:913\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer._get_model_for_prediction\u001b[0;34m(self, model, verbose)\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    912\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 913\u001b[0m         best_model_name: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_model_best\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    914\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_best \u001b[38;5;241m=\u001b[39m best_model_name\n\u001b[1;32m    915\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "File \u001b[0;32m~/GitHub/WF-ML/env/lib/python3.11/site-packages/autogluon/timeseries/trainer/abstract_trainer.py:407\u001b[0m, in \u001b[0;36mAbstractTimeSeriesTrainer.get_model_best\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m models \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_model_names()\n\u001b[1;32m    406\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m models:\n\u001b[0;32m--> 407\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrainer has no fit models that can predict.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(models) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m models[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mValueError\u001b[0m: Trainer has no fit models that can predict."
     ]
    }
   ],
   "source": [
    "# Define the forecast horizon (e.g., forecast the next 24 hours)\n",
    "prediction_length = 12\n",
    "\n",
    "# Instantiate the DeepAR model using AutoGluon\n",
    "model = DeepAR(prediction_length=prediction_length, freq=\"H\")\n",
    "\n",
    "# Train the model on the training data\n",
    "model.train(train1, target_column=\"query_count\")\n",
    "\n",
    "# Generate predictions on the test data\n",
    "predictions_df = model.predict(test1, target_column=\"query_count\")\n",
    "print(\"Predictions:\")\n",
    "print(predictions_df.head())\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "evaluation_results = model.evaluate(test1, target_column=\"query_count\")\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(evaluation_results)\n",
    "\n",
    "# Save the trained model to disk\n",
    "model.save_model(\"deepar_autogluon_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sagnikdas/GitHub/g8/.pyenv/lib/python3.11/site-packages/autogluon/timeseries/predictor.py:197: FutureWarning: 'H' is deprecated and will be removed in a future version, please use 'h' instead.\n",
      "  std_freq = pd.tseries.frequencies.to_offset(self.freq).freqstr\n",
      "Frequency 'H' stored as 'h'\n",
      "Beginning AutoGluon training...\n",
      "AutoGluon will save models to '/Users/sagnikdas/GitHub/g8/AutogluonModels/ag-20250215_120457'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "=================== System Info ===================\n",
      "AutoGluon Version:  1.2\n",
      "Python Version:     3.11.10\n",
      "Operating System:   Darwin\n",
      "Platform Machine:   arm64\n",
      "Platform Version:   Darwin Kernel Version 24.3.0: Thu Jan  2 20:24:06 PST 2025; root:xnu-11215.81.4~3/RELEASE_ARM64_T8103\n",
      "CPU Count:          8\n",
      "GPU Count:          0\n",
      "Memory Avail:       1.63 GB / 8.00 GB (20.4%)\n",
      "Disk Space Avail:   61.92 GB / 228.27 GB (27.1%)\n",
      "===================================================\n",
      "\n",
      "Fitting with arguments:\n",
      "{'enable_ensemble': True,\n",
      " 'eval_metric': WQL,\n",
      " 'freq': 'h',\n",
      " 'hyperparameters': {'DeepAR': {'batch_size': 32,\n",
      "                                'context_length': 24,\n",
      "                                'dropout': 0.1,\n",
      "                                'epochs': 50,\n",
      "                                'hidden_size': 40,\n",
      "                                'learning_rate': 0.001,\n",
      "                                'num_layers': 2}},\n",
      " 'known_covariates_names': [],\n",
      " 'num_val_windows': 1,\n",
      " 'prediction_length': 24,\n",
      " 'quantile_levels': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9],\n",
      " 'random_seed': 123,\n",
      " 'refit_every_n_windows': 1,\n",
      " 'refit_full': False,\n",
      " 'skip_model_selection': False,\n",
      " 'target': 'query_count',\n",
      " 'verbosity': 2}\n",
      "\n",
      "train_data with frequency 'None' has been resampled to frequency 'h'.\n",
      "Provided train_data has 1920 rows (NaN fraction=0.1%), 1 time series. Median time series length is 1920 (min=1920, max=1920). \n",
      "\n",
      "Provided data contains following columns:\n",
      "\ttarget: 'query_count'\n",
      "\tpast_covariates:\n",
      "\t\tcategorical:        []\n",
      "\t\tcontinuous (float): ['instance_id', 'runtime', 'bytes_scanned']\n",
      "\n",
      "To learn how to fix incorrectly inferred types, please see documentation for TimeSeriesPredictor.fit\n",
      "\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'WQL'\n",
      "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
      "===================================================\n",
      "\n",
      "Starting training. Start time is 2025-02-15 13:05:00\n",
      "Models that will be trained: ['DeepAR']\n",
      "Training timeseries model DeepAR. \n",
      "\t-0.7405       = Validation score (-WQL)\n",
      "\t46.55   s     = Training runtime\n",
      "\t0.06    s     = Validation (prediction) runtime\n",
      "Not fitting ensemble as only 1 model was trained.\n",
      "Training complete. Models trained: ['DeepAR']\n",
      "Total runtime: 46.63 s\n",
      "Best model: DeepAR\n",
      "Best model score: -0.7405\n",
      "Model not specified in predict, will default to the model with the best validation score: DeepAR\n",
      "Model not specified in predict, will default to the model with the best validation score: DeepAR\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training completed. Models trained: <bound method TimeSeriesPredictor.model_names of <autogluon.timeseries.predictor.TimeSeriesPredictor object at 0x103639c90>>\n",
      "Test Data Index Type: <class 'pandas.core.indexes.base.Index'>\n",
      "Predictions Index Type: <class 'pandas.core.indexes.multi.MultiIndex'>\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot include dtype 'M' in a buffer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Make predictions\u001b[39;00m\n\u001b[1;32m      5\u001b[0m predictions1 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test1)\n\u001b[0;32m----> 6\u001b[0m metrics1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Make predictions for second split\u001b[39;00m\n\u001b[1;32m      9\u001b[0m predictions2 \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(test2)\n",
      "File \u001b[0;32m~/GitHub/g8/utility/baseline_models.py:102\u001b[0m, in \u001b[0;36mDeepARModel.evaluate\u001b[0;34m(self, test_data)\u001b[0m\n\u001b[1;32m     99\u001b[0m     predictions\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mforecast_time\u001b[39m\u001b[38;5;124m\"\u001b[39m, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Align forecast index\u001b[39;00m\n\u001b[1;32m    101\u001b[0m \u001b[38;5;66;03m# Reindex predictions to match test_data timestamps\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mpredictions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39misnull()\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m⚠️ Warning: Predictions contain NaN values after reindexing!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/GitHub/g8/.pyenv/lib/python3.11/site-packages/pandas/core/frame.py:5378\u001b[0m, in \u001b[0;36mDataFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5359\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[1;32m   5360\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,\n\u001b[1;32m   5361\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5376\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5377\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m-> 5378\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5379\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5380\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5381\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5382\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5383\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5384\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5385\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5387\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5389\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHub/g8/.pyenv/lib/python3.11/site-packages/pandas/core/generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[0;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[1;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[1;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[0;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m   5612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/GitHub/g8/.pyenv/lib/python3.11/site-packages/pandas/core/generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[0;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[1;32m   5630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[0;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[1;32m   5635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[1;32m   5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[1;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[1;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[1;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[1;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   5643\u001b[0m )\n",
      "File \u001b[0;32m~/GitHub/g8/.pyenv/lib/python3.11/site-packages/pandas/core/indexes/base.py:4433\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[0;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[1;32m   4430\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   4431\u001b[0m             indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n\u001b[0;32m-> 4433\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_reindex_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreserve_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4434\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m target, indexer\n",
      "File \u001b[0;32m~/GitHub/g8/.pyenv/lib/python3.11/site-packages/pandas/core/indexes/multi.py:2717\u001b[0m, in \u001b[0;36mMultiIndex._wrap_reindex_result\u001b[0;34m(self, target, indexer, preserve_names)\u001b[0m\n\u001b[1;32m   2715\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2716\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2717\u001b[0m         target \u001b[38;5;241m=\u001b[39m \u001b[43mMultiIndex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_tuples\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2718\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   2719\u001b[0m         \u001b[38;5;66;03m# not all tuples, see test_constructor_dict_multiindex_reindex_flat\u001b[39;00m\n\u001b[1;32m   2720\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m target\n",
      "File \u001b[0;32m~/GitHub/g8/.pyenv/lib/python3.11/site-packages/pandas/core/indexes/multi.py:222\u001b[0m, in \u001b[0;36mnames_compat.<locals>.new_meth\u001b[0;34m(self_or_cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m    220\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mpop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\u001b[43mself_or_cls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/GitHub/g8/.pyenv/lib/python3.11/site-packages/pandas/core/indexes/multi.py:617\u001b[0m, in \u001b[0;36mMultiIndex.from_tuples\u001b[0;34m(cls, tuples, sortorder, names)\u001b[0m\n\u001b[1;32m    614\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tuples, Index):\n\u001b[1;32m    615\u001b[0m         tuples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(tuples\u001b[38;5;241m.\u001b[39m_values)\n\u001b[0;32m--> 617\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtuples_to_object_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtuples\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m    618\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tuples, \u001b[38;5;28mlist\u001b[39m):\n\u001b[1;32m    619\u001b[0m     arrays \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(lib\u001b[38;5;241m.\u001b[39mto_object_array_tuples(tuples)\u001b[38;5;241m.\u001b[39mT)\n",
      "File \u001b[0;32mlib.pyx:3029\u001b[0m, in \u001b[0;36mpandas._libs.lib.tuples_to_object_array\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot include dtype 'M' in a buffer"
     ]
    }
   ],
   "source": [
    "predictions = deepar.predict(test1, target_column=\"query_count\")\n",
    "metrics = deepar.evaluate(test1, target_column=\"query_count\")\n",
    "print(\"Model Evaluation:\", metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
